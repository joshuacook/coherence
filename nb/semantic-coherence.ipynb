{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wiki_df = pd.read_json(\"../data/wikidata_pandas.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import pandas as pd\n",
    "\n",
    "def no_number_preprocessor(tokens):\n",
    "    r = re.sub('(\\d)+', '', tokens.lower())\n",
    "    return r\n",
    "  \n",
    "vectorizer = TfidfVectorizer(stop_words='english', preprocessor=no_number_preprocessor)\n",
    "bag_of_words = vectorizer.fit_transform(wiki_df.text)\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "lsa = svd.fit_transform(bag_of_words)\n",
    "\n",
    "topic_encoded_df = pd.DataFrame(lsa)\n",
    "dictionary = vectorizer.get_feature_names()\n",
    "encoding_matrix = pd.DataFrame(svd.components_,\n",
    "                               columns=dictionary).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret The Encoding Matrix\n",
    "\n",
    "Note that topic 1 is not semantically coherent (mix of baseball and jazz words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encoding_matrix[[0,1,2]].sort_values(0, ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret The Encoding Matrix\n",
    "\n",
    "Note that topic 2 is semantically coherent (just baseball words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encoding_matrix[[0,1,2]].sort_values(1, ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret The Encoding Matrix\n",
    "\n",
    "Note that topic 3 is semantically coherent (just jazz words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encoding_matrix[[0,1,2]].sort_values(2, ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Model\n",
    "\n",
    "A classical method for building a cluster model. \n",
    "\n",
    "![](https://www.evernote.com/l/AAGuoaYyLFNOLL7fUDxfug7PS3ugGJt-68MB/image.png)\n",
    "\n",
    "1. Raw data (bag of words)\n",
    "2. Used to create Low-Rank Model (LSA)\n",
    "3. Fit cluster model to that (GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the LRM is constructed by performing an eigenvector (or variant) decomposition on the original data and selecting the vectors from the decomposed matrix with the highest eigenvalues i.e. the first _n_ vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Clustering via Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2)\n",
    "labels = gmm.fit_predict(topic_encoded_df[range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "fig.suptitle('GMM prepared on first twenty vectors from topic model', fontsize=16)\n",
    "for val in wiki_df.category.unique():\n",
    "    topic_1 = topic_encoded_df[wiki_df.category == val][0].values\n",
    "    topic_2 = topic_encoded_df[wiki_df.category == val][1].values\n",
    "    print(val)\n",
    "    color = \"red\" if val == \"Baseball\" else \"green\"\n",
    "    label = val\n",
    "    ax[0].scatter(topic_1, topic_2, c=color, alpha=0.3, label=label)\n",
    "  \n",
    "topic_encoded_df.plot(kind=\"scatter\", x=0, y=1, c=[\"red\" if label == 0 else \"green\" for label in labels], ax=ax[1])  \n",
    "# made the colors represent different books\n",
    "\n",
    "ax[0].set_xlabel('topic_1')\n",
    "ax[0].set_ylabel('topic_2')\n",
    "ax[0].axvline(linewidth=0.5)\n",
    "ax[0].axhline(linewidth=0.5)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "labels = gmm.fit_predict(topic_encoded_df[range(1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "fig.suptitle('GMM prepared on first twenty vectors from topic model', fontsize=16)\n",
    "for val in wiki_df.category.unique():\n",
    "    topic_1 = topic_encoded_df[wiki_df.category == val][1].values\n",
    "    topic_2 = topic_encoded_df[wiki_df.category == val][2].values\n",
    "    print(val)\n",
    "    color = \"red\" if val == \"Baseball\" else \"green\"\n",
    "    label = val\n",
    "    ax[0].scatter(topic_1, topic_2, c=color, alpha=0.3, label=label)\n",
    "  \n",
    "topic_encoded_df.plot(kind=\"scatter\", x=1, y=2, alpha=0.3, c=[\"red\" if label == 1 else \"green\" for label in labels], ax=ax[1])  \n",
    "# made the colors represent different books\n",
    "\n",
    "ax[0].set_xlabel('topic_1')\n",
    "ax[0].set_ylabel('topic_2')\n",
    "ax[0].axvline(linewidth=0.5)\n",
    "ax[0].axhline(linewidth=0.5)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_lists = [\n",
    "    [dictionary.index(word) for word in \n",
    "        list(encoding_matrix[i].sort_values(ascending=False).head(20).index.values)\n",
    "    ]\n",
    "    for i in range(50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(bag_of_words.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def PMI(i1, i2):\n",
    "    return mutual_info_regression(bag_of_words[[i1]], bag_of_words[i2])[0]\n",
    "\n",
    "def coherence(topic_indices):\n",
    "    pairwise_indices = list(combinations(topic_indices, 2))\n",
    "    sum = 0\n",
    "    for pair in pairwise_indices:\n",
    "        sum += PMI(*pair)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherences = [coherence(topic_list) for topic_list in topic_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "American Passtimes",
  "notebookId": 1787824012696846
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
